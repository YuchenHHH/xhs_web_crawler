"""
æ‰¹é‡å›¾ç‰‡ç­›é€‰è„šæœ¬ï¼šæ ¹æ®æè¿°ä¿ç•™ç¬¦åˆå†…å®¹çš„å›¾ç‰‡ã€‚

ç”¨æ³•ç¤ºä¾‹ï¼š
    python scripts/batch_filter_images.py \\
        --input-dir output/æ¿è±†è…_20251205_153136 \\
        --description "åªä¿ç•™åŒ…å«æˆå“èœè‚´çš„å›¾ç‰‡ï¼Œæ’é™¤åŸæ–™ã€åŒ…è£…ã€èœå•ã€æ–‡å­—æˆªå›¾" \\
        --output-dir filtered_images
"""
import argparse
import asyncio
import base64
import json
import os
import shutil
from pathlib import Path
from typing import Dict, List, Tuple

from dotenv import load_dotenv
from openai import AsyncOpenAI


SUPPORTED_EXTS = {".png", ".jpg", ".jpeg", ".webp"}


def _encode_image(path: Path) -> str:
    return base64.b64encode(path.read_bytes()).decode("utf-8")


def _build_prompt(description: str) -> str:
    return f"""ä½ æ˜¯å›¾ç‰‡å®¡æ ¸åŠ©æ‰‹ï¼Œéœ€è¦åˆ¤æ–­å›¾ç‰‡æ˜¯å¦ç¬¦åˆç”¨æˆ·æè¿°ã€‚

ã€ç”¨æˆ·æè¿°ã€‘ï¼š
{description}

ã€ä»»åŠ¡ã€‘ï¼š
1. ä»”ç»†è§‚å¯Ÿå›¾ç‰‡å†…å®¹ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ç”¨æˆ·æè¿°é«˜åº¦ç›¸å…³ã€‚
2. å¦‚æœå›¾ç‰‡æ˜æ˜¾ä¸ç¬¦åˆæè¿°ï¼ˆé¢˜æä¸ç¬¦ã€çº¯æ–‡å­—æˆªå›¾ã€ä¸ä¸»é¢˜æ— å…³çš„ç‰©ä½“/åœºæ™¯ï¼‰ï¼Œæ ‡è®°ä¸ºä¸ä¿ç•™ã€‚
3. å¯¹æ¨¡ç³Šã€è£å‰ªè¿‡å°ã€æ— æ³•è¾¨è®¤çš„å›¾ç‰‡ï¼Œå®å¯ä¸ä¿ç•™ã€‚

ã€è¾“å‡ºã€‘ï¼š
è¿”å›ä¸¥æ ¼ JSONï¼š
{{
  "keep": true,   // true=ä¿ç•™ï¼Œfalse=ä¸¢å¼ƒ
  "reason": "ç®€è¦è¯´æ˜åˆ¤æ–­ä¾æ®"
}}"""


async def _judge_image(
    client: AsyncOpenAI,
    model: str,
    image_path: Path,
    prompt: str,
) -> Tuple[bool, str]:
    """è°ƒç”¨ GPT-4o åˆ¤æ–­æ˜¯å¦ä¿ç•™å›¾ç‰‡ã€‚"""
    base64_image = _encode_image(image_path)
    response = await client.chat.completions.create(
        model=model,
        temperature=0,
        response_format={"type": "json_object"},
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{base64_image}",
                            "detail": "high",
                        },
                    },
                ],
            }
        ],
    )
    raw = response.choices[0].message.content or "{}"
    try:
        parsed = json.loads(raw)
        keep = bool(parsed.get("keep"))
        reason = str(parsed.get("reason", "")).strip()
    except Exception:
        keep = False
        reason = f"è§£æå¤±è´¥: {raw[:80]}"
    return keep, reason


async def _process_images(
    image_paths: List[Path],
    description: str,
    output_dir: Path,
    concurrency: int,
    model: str,
) -> List[Dict]:
    prompt = _build_prompt(description)
    client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))
    semaphore = asyncio.Semaphore(concurrency)
    results: List[Dict] = []

    async def _worker(path: Path):
        async with semaphore:
            keep, reason = await _judge_image(client, model, path, prompt)
            if keep:
                target = output_dir / path.name
                target.parent.mkdir(parents=True, exist_ok=True)
                shutil.copy2(path, target)
            results.append(
                {
                    "file": str(path),
                    "keep": keep,
                    "reason": reason,
                }
            )

    await asyncio.gather(*[_worker(p) for p in image_paths])
    return results


def main():
    load_dotenv()

    parser = argparse.ArgumentParser(description="æ‰¹é‡ç­›é€‰å›¾ç‰‡ï¼Œä¿ç•™ç¬¦åˆæè¿°çš„æ–‡ä»¶ã€‚")
    parser.add_argument(
        "--input-dir",
        required=True,
        help="å¾…ç­›é€‰å›¾ç‰‡æ‰€åœ¨ç›®å½•ï¼ˆä¼šé€’å½’æ‰«æï¼‰",
    )
    parser.add_argument(
        "--description",
        required=True,
        help="å›¾ç‰‡å†…å®¹æè¿°ï¼Œç¬¦åˆçš„å°†è¢«ä¿ç•™",
    )
    parser.add_argument(
        "--output-dir",
        default="filtered_images",
        help="è¾“å‡ºç›®å½•ï¼Œä¿å­˜ä¿ç•™çš„å›¾ç‰‡åŠç»“æœæ‘˜è¦",
    )
    parser.add_argument(
        "--concurrency",
        type=int,
        default=3,
        help="å¹¶å‘è°ƒç”¨æ•°ï¼Œè¿‡å¤§å¯èƒ½è§¦å‘é™æµ",
    )
    parser.add_argument(
        "--model",
        default=os.getenv("OPENAI_MODEL", "gpt-4o"),
        help="ä½¿ç”¨çš„ OpenAI æ¨¡å‹ï¼Œé»˜è®¤å–ç¯å¢ƒå˜é‡ OPENAI_MODEL æˆ– gpt-4o",
    )
    args = parser.parse_args()

    input_dir = Path(args.input_dir)
    output_dir = Path(args.output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    if not input_dir.exists():
        raise FileNotFoundError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")

    # æ”¶é›†å›¾ç‰‡
    image_paths = [
        p for p in input_dir.rglob("*") if p.suffix.lower() in SUPPORTED_EXTS
    ]
    if not image_paths:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶")
        return

    print(f"ğŸ¯ æè¿°: {args.description}")
    print(f"ğŸ“‚ è¾“å…¥: {input_dir} ï¼ˆå…± {len(image_paths)} å¼ ï¼‰")
    print(f"ğŸ“ è¾“å‡º: {output_dir}")
    print(f"ğŸ§  æ¨¡å‹: {args.model}")
    print(f"ğŸš¦ å¹¶å‘: {args.concurrency}\n")

    results = asyncio.run(
        _process_images(
            image_paths=image_paths,
            description=args.description,
            output_dir=output_dir,
            concurrency=args.concurrency,
            model=args.model,
        )
    )

    # å†™å‡ºæ‘˜è¦
    summary_path = output_dir / "filter_results.json"
    summary = {
        "description": args.description,
        "model": args.model,
        "kept": len([r for r in results if r["keep"]]),
        "total": len(results),
        "details": results,
    }
    summary_path.write_text(json.dumps(summary, ensure_ascii=False, indent=2))
    print(f"\nâœ… ç­›é€‰å®Œæˆï¼Œä¿ç•™ {summary['kept']} / {summary['total']} å¼ ")
    print(f"ğŸ“ ç»“æœå·²å†™å…¥: {summary_path}")


if __name__ == "__main__":
    main()
